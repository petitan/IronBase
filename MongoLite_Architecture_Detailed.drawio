<mxfile host="app.diagrams.net" modified="2025-11-12T00:00:00.000Z" agent="Claude Code" version="24.0.0" etag="MongoLite-v2-detailed" type="device">
  <diagram name="MongoLite Detailed Architecture" id="detailed-arch">
    <mxGraphModel dx="2400" dy="1400" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="3200" pageHeight="2400" math="0" shadow="0">
      <root>
        <mxCell id="0" />
        <mxCell id="1" parent="0" />

        <!-- ========== TITLE ========== -->
        <mxCell id="title" value="MongoLite Architecture - Detailed Implementation" style="text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontSize=28;fontStyle=1" vertex="1" parent="1">
          <mxGeometry x="800" y="20" width="1600" height="50" as="geometry" />
        </mxCell>

        <mxCell id="subtitle" value="Version 2 - Dynamic Metadata | Detailed structs, functions, and algorithms" style="text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontSize=16;fontStyle=2;fontColor=#666666;" vertex="1" parent="1">
          <mxGeometry x="800" y="70" width="1600" height="30" as="geometry" />
        </mxCell>

        <!-- ========== LAYER 1: Python API ========== -->
        <mxCell id="python_layer" value="Python API Layer (PyO3 Bindings)" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=#6c8ebf;verticalAlign=top;fontSize=16;fontStyle=1;align=center;" vertex="1" parent="1">
          <mxGeometry x="40" y="120" width="3120" height="280" as="geometry" />
        </mxCell>

        <!-- IronBase Class -->
        <mxCell id="python_ironbase" value="IronBase (bindings/python/src/lib.rs)" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#b1ddf0;strokeColor=#10739e;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="80" y="165" width="480" height="215" as="geometry" />
        </mxCell>

        <mxCell id="python_ironbase_code" value="&#xa;#[pyclass]&#xa;pub struct IronBase {&#xa;    db: Arc&lt;RwLock&lt;Database&gt;&gt;,&#xa;    path: String,&#xa;}&#xa;&#xa;#[pymethods]&#xa;impl IronBase {&#xa;    #[new]&#xa;    fn __init__(path: &amp;str) -&gt; PyResult&lt;Self&gt;&#xa;    &#xa;    fn collection(&amp;self, name: &amp;str) -&gt; PyResult&lt;Collection&gt;&#xa;    &#xa;    fn list_collections(&amp;self) -&gt; PyResult&lt;Vec&lt;String&gt;&gt;&#xa;    &#xa;    fn drop_collection(&amp;mut self, name: &amp;str) -&gt; PyResult&lt;()&gt;&#xa;    &#xa;    fn close(&amp;mut self) -&gt; PyResult&lt;()&gt;&#xa;    &#xa;    fn flush(&amp;mut self) -&gt; PyResult&lt;()&gt;  // Force metadata flush&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=10;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="90" y="190" width="460" height="180" as="geometry" />
        </mxCell>

        <!-- Collection Class -->
        <mxCell id="python_collection" value="Collection (bindings/python/src/lib.rs)" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#b1ddf0;strokeColor=#10739e;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="600" y="165" width="720" height="215" as="geometry" />
        </mxCell>

        <mxCell id="python_collection_code" value="&#xa;#[pyclass]&#xa;pub struct Collection {&#xa;    collection: Arc&lt;RwLock&lt;crate::collection::Collection&gt;&gt;,&#xa;    name: String,&#xa;}&#xa;&#xa;#[pymethods]&#xa;impl Collection {&#xa;    fn insert_one(&amp;mut self, py: Python, document: &amp;PyDict) -&gt; PyResult&lt;PyObject&gt;&#xa;        // Converts PyDict -&gt; JSON Value -&gt; Rust CRUD&#xa;    &#xa;    fn insert_many(&amp;mut self, py: Python, documents: &amp;PyList) -&gt; PyResult&lt;PyObject&gt;&#xa;        // Batch insert with transaction-like behavior&#xa;    &#xa;    fn find(&amp;self, py: Python, filter: &amp;PyDict) -&gt; PyResult&lt;PyObject&gt;&#xa;        // Returns iterator over matching documents&#xa;    &#xa;    fn find_one(&amp;self, py: Python, filter: &amp;PyDict) -&gt; PyResult&lt;Option&lt;PyObject&gt;&gt;&#xa;    &#xa;    fn update_one(&amp;mut self, filter: &amp;PyDict, update: &amp;PyDict) -&gt; PyResult&lt;PyObject&gt;&#xa;    &#xa;    fn update_many(&amp;mut self, filter: &amp;PyDict, update: &amp;PyDict) -&gt; PyResult&lt;PyObject&gt;&#xa;    &#xa;    fn delete_one(&amp;mut self, filter: &amp;PyDict) -&gt; PyResult&lt;PyObject&gt;&#xa;    &#xa;    fn delete_many(&amp;mut self, filter: &amp;PyDict) -&gt; PyResult&lt;PyObject&gt;&#xa;    &#xa;    fn count_documents(&amp;self, filter: &amp;PyDict) -&gt; PyResult&lt;u64&gt;&#xa;        // Uses catalog size for {} query, else full scan&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="610" y="190" width="700" height="180" as="geometry" />
        </mxCell>

        <!-- Python Utils -->
        <mxCell id="python_utils" value="Python Type Conversion" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#b1ddf0;strokeColor=#10739e;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="1360" y="165" width="480" height="215" as="geometry" />
        </mxCell>

        <mxCell id="python_utils_code" value="&#xa;fn python_to_json(py: Python, obj: &amp;PyAny) -&gt; Result&lt;Value&gt; {&#xa;    // PyDict -&gt; JSON Object&#xa;    // PyList -&gt; JSON Array&#xa;    // PyInt/Float/String/Bool -&gt; JSON primitives&#xa;    // PyBytes -&gt; Base64 string&#xa;    // datetime -&gt; ISO 8601 string&#xa;    // ObjectId -&gt; {&quot;$oid&quot;: &quot;...&quot;}&#xa;}&#xa;&#xa;fn json_to_python(py: Python, value: &amp;Value) -&gt; PyResult&lt;PyObject&gt; {&#xa;    // Reverse conversion&#xa;    // Handles MongoDB extended JSON:&#xa;    //   {&quot;$oid&quot;: &quot;...&quot;} -&gt; ObjectId&#xa;    //   {&quot;$date&quot;: ...} -&gt; datetime&#xa;    //   {&quot;$binary&quot;: ...} -&gt; bytes&#xa;    //   {&quot;$numberInt&quot;: ...} -&gt; int&#xa;    //   {&quot;$numberLong&quot;: ...} -&gt; int&#xa;}&#xa;&#xa;fn ensure_collection_field(value: &amp;mut Value, coll: &amp;str) {&#xa;    // Injects &quot;_collection&quot; field into documents&#xa;    // Required for multi-collection storage&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="1370" y="190" width="460" height="180" as="geometry" />
        </mxCell>

        <!-- PyO3 Bridge -->
        <mxCell id="pyo3_bridge" value="PyO3 Bridge Mechanism" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#b1ddf0;strokeColor=#10739e;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="1880" y="165" width="420" height="215" as="geometry" />
        </mxCell>

        <mxCell id="pyo3_bridge_code" value="&#xa;#[pymodule]&#xa;fn ironbase(_py: Python, m: &amp;PyModule) -&gt; PyResult&lt;()&gt; {&#xa;    m.add_class::&lt;IronBase&gt;()?;&#xa;    m.add_class::&lt;Collection&gt;()?;&#xa;    Ok(())&#xa;}&#xa;&#xa;// Thread Safety:&#xa;// - Arc&lt;RwLock&lt;T&gt;&gt; allows shared access&#xa;// - Python GIL ensures thread safety on Py side&#xa;// - Rust side uses parking_lot::RwLock&#xa;&#xa;// Error Handling:&#xa;// - MongoLiteError -&gt; PyErr conversion&#xa;// - IoError -&gt; PyIOError&#xa;// - NotFound -&gt; PyKeyError&#xa;// - Corruption -&gt; PyRuntimeError&#xa;// - Serialization -&gt; PyValueError&#xa;&#xa;// Build with Maturin:&#xa;// $ maturin develop  (debug)&#xa;// $ maturin build --release&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="1890" y="190" width="400" height="180" as="geometry" />
        </mxCell>

        <!-- ========== LAYER 2: Rust Core ========== -->
        <mxCell id="rust_layer" value="Rust Core Library (ironbase-core/src/)" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#d5e8d4;strokeColor=#82b366;verticalAlign=top;fontSize=16;fontStyle=1;align=center;" vertex="1" parent="1">
          <mxGeometry x="40" y="440" width="3120" height="480" as="geometry" />
        </mxCell>

        <!-- database.rs -->
        <mxCell id="rust_database" value="database.rs" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#b9e0a5;strokeColor=#5a8f3d;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="80" y="485" width="450" height="410" as="geometry" />
        </mxCell>

        <mxCell id="rust_database_code" value="&#xa;pub struct Database {&#xa;    storage: Arc&lt;RwLock&lt;StorageEngine&gt;&gt;,&#xa;    wal: Option&lt;WriteAheadLog&gt;,&#xa;}&#xa;&#xa;impl Database {&#xa;    pub fn open(path: &amp;str) -&gt; Result&lt;Self&gt; {&#xa;        let storage = StorageEngine::open(path)?;&#xa;        let wal = WriteAheadLog::open(&#xa;            format!(&quot;{}.wal&quot;, path)&#xa;        )?;&#xa;        &#xa;        // WAL Recovery:&#xa;        wal.replay(|entry| {&#xa;            storage.apply_wal_entry(entry)?;&#xa;        })?;&#xa;        &#xa;        Ok(Database { storage, wal })&#xa;    }&#xa;    &#xa;    pub fn collection(&amp;self, name: &amp;str) -&gt; Result&lt;Collection&gt; {&#xa;        let mut storage = self.storage.write();&#xa;        &#xa;        if !storage.has_collection(name) {&#xa;            storage.create_collection(name)?;&#xa;            // NOTE: No metadata flush here!&#xa;            // Lazy flush on close/compact&#xa;        }&#xa;        &#xa;        Ok(Collection::new(&#xa;            name.to_string(),&#xa;            Arc::clone(&amp;self.storage)&#xa;        ))&#xa;    }&#xa;    &#xa;    pub fn close(&amp;mut self) -&gt; Result&lt;()&gt; {&#xa;        // Flush metadata before closing&#xa;        self.storage.write().flush_metadata()?;&#xa;        self.wal.take().map(|w| w.close());&#xa;        Ok(())&#xa;    }&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="90" y="510" width="430" height="370" as="geometry" />
        </mxCell>

        <!-- collection.rs -->
        <mxCell id="rust_collection_rust" value="collection.rs" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#b9e0a5;strokeColor=#5a8f3d;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="570" y="485" width="600" height="410" as="geometry" />
        </mxCell>

        <mxCell id="rust_collection_rust_code" value="&#xa;pub struct Collection {&#xa;    name: String,&#xa;    storage: Arc&lt;RwLock&lt;StorageEngine&gt;&gt;,&#xa;}&#xa;&#xa;impl Collection {&#xa;    pub fn insert_one(&amp;mut self, mut doc: Value) -&gt; Result&lt;InsertOneResult&gt; {&#xa;        // 1. Generate _id if missing&#xa;        let doc_id = if let Some(id_val) = doc.get(&quot;_id&quot;) {&#xa;            serde_json::from_value(id_val.clone())?&#xa;        } else {&#xa;            let new_id = self.generate_id()?;&#xa;            doc[&quot;_id&quot;] = serde_json::to_value(&amp;new_id)?;&#xa;            new_id&#xa;        };&#xa;        &#xa;        // 2. Inject _collection field&#xa;        doc[&quot;_collection&quot;] = Value::String(self.name.clone());&#xa;        &#xa;        // 3. Serialize to JSON bytes&#xa;        let doc_bytes = serde_json::to_vec(&amp;doc)?;&#xa;        &#xa;        // 4. Write to storage (acquires write lock)&#xa;        let mut storage = self.storage.write();&#xa;        let offset = storage.write_document(&amp;self.name, &amp;doc_id, &amp;doc_bytes)?;&#xa;        &#xa;        // 5. Write to WAL for durability&#xa;        storage.wal_append(WalEntry::Insert {&#xa;            collection: self.name.clone(),&#xa;            doc_id: doc_id.clone(),&#xa;            data: doc_bytes,&#xa;        })?;&#xa;        &#xa;        Ok(InsertOneResult { inserted_id: doc_id })&#xa;    }&#xa;    &#xa;    pub fn find(&amp;self, filter: Value) -&gt; Result&lt;Vec&lt;Value&gt;&gt; {&#xa;        let storage = self.storage.read();  // Read lock only&#xa;        let meta = storage.get_collection_meta(&amp;self.name)?;&#xa;        &#xa;        let mut results = Vec::new();&#xa;        for (&amp;offset) in meta.document_catalog.values() {&#xa;            let doc_bytes = storage.read_data(offset)?;&#xa;            let doc: Value = serde_json::from_slice(&amp;doc_bytes)?;&#xa;            &#xa;            // Skip tombstones&#xa;            if doc.get(&quot;_tombstone&quot;).and_then(|v| v.as_bool()).unwrap_or(false) {&#xa;                continue;&#xa;            }&#xa;            &#xa;            // Apply filter&#xa;            if matches_filter(&amp;doc, &amp;filter)? {&#xa;                results.push(doc);&#xa;            }&#xa;        }&#xa;        &#xa;        Ok(results)&#xa;    }&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="580" y="510" width="580" height="370" as="geometry" />
        </mxCell>

        <!-- document.rs -->
        <mxCell id="rust_document" value="document.rs" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#b9e0a5;strokeColor=#5a8f3d;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="1210" y="485" width="400" height="410" as="geometry" />
        </mxCell>

        <mxCell id="rust_document_code" value="&#xa;#[derive(Debug, Clone, PartialEq, Eq, Hash)]&#xa;#[derive(Serialize, Deserialize)]&#xa;#[serde(untagged)]  // JSON: 123 or &quot;abc&quot; or {&quot;$oid&quot;:...}&#xa;pub enum DocumentId {&#xa;    Int(i64),&#xa;    String(String),&#xa;    ObjectId([u8; 12]),  // MongoDB ObjectId&#xa;}&#xa;&#xa;impl DocumentId {&#xa;    pub fn from_int(n: i64) -&gt; Self {&#xa;        DocumentId::Int(n)&#xa;    }&#xa;    &#xa;    pub fn from_string(s: String) -&gt; Self {&#xa;        DocumentId::String(s)&#xa;    }&#xa;    &#xa;    pub fn new_object_id() -&gt; Self {&#xa;        let mut bytes = [0u8; 12];&#xa;        // [4B timestamp][5B random][3B counter]&#xa;        bytes[0..4].copy_from_slice(&#xa;            &amp;SystemTime::now()&#xa;                .duration_since(UNIX_EPOCH)&#xa;                .unwrap()&#xa;                .as_secs()&#xa;                .to_be_bytes()[4..]&#xa;        );&#xa;        bytes[4..9].copy_from_slice(&amp;rand::random::&lt;[u8; 5]&gt;());&#xa;        let counter = COUNTER.fetch_add(1, Ordering::SeqCst);&#xa;        bytes[9..12].copy_from_slice(&amp;counter.to_be_bytes()[5..]);&#xa;        DocumentId::ObjectId(bytes)&#xa;    }&#xa;}&#xa;&#xa;// Custom serialization in catalog_serde.rs:&#xa;// [type_tag: u8, value: bytes, offset: u64]&#xa;// This preserves type info during metadata persistence&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="1220" y="510" width="380" height="370" as="geometry" />
        </mxCell>

        <!-- query.rs -->
        <mxCell id="rust_query" value="query.rs" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#b9e0a5;strokeColor=#5a8f3d;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="1650" y="485" width="580" height="410" as="geometry" />
        </mxCell>

        <mxCell id="rust_query_code" value="&#xa;pub fn matches_filter(doc: &amp;Value, filter: &amp;Value) -&gt; Result&lt;bool&gt; {&#xa;    // Empty filter matches all&#xa;    if filter.as_object().map(|o| o.is_empty()).unwrap_or(false) {&#xa;        return Ok(true);&#xa;    }&#xa;    &#xa;    let filter_obj = filter.as_object().ok_or(QueryError)?;&#xa;    &#xa;    for (key, value) in filter_obj {&#xa;        match key.as_str() {&#xa;            &quot;$and&quot; =&gt; {&#xa;                let conditions = value.as_array().ok_or(QueryError)?;&#xa;                for cond in conditions {&#xa;                    if !matches_filter(doc, cond)? { return Ok(false); }&#xa;                }&#xa;            }&#xa;            &quot;$or&quot; =&gt; {&#xa;                let conditions = value.as_array().ok_or(QueryError)?;&#xa;                let mut any_match = false;&#xa;                for cond in conditions {&#xa;                    if matches_filter(doc, cond)? { any_match = true; break; }&#xa;                }&#xa;                if !any_match { return Ok(false); }&#xa;            }&#xa;            field_name =&gt; {&#xa;                let doc_value = doc.get(field_name);&#xa;                &#xa;                if let Some(operator_obj) = value.as_object() {&#xa;                    // Operator query: {&quot;age&quot;: {&quot;$gt&quot;: 18}}&#xa;                    for (op, op_value) in operator_obj {&#xa;                        match op.as_str() {&#xa;                            &quot;$eq&quot; =&gt; if doc_value != Some(op_value) { return Ok(false); }&#xa;                            &quot;$ne&quot; =&gt; if doc_value == Some(op_value) { return Ok(false); }&#xa;                            &quot;$gt&quot; =&gt; if !compare_gt(doc_value, op_value)? { return Ok(false); }&#xa;                            &quot;$gte&quot; =&gt; if !compare_gte(doc_value, op_value)? { return Ok(false); }&#xa;                            &quot;$lt&quot; =&gt; if !compare_lt(doc_value, op_value)? { return Ok(false); }&#xa;                            &quot;$lte&quot; =&gt; if !compare_lte(doc_value, op_value)? { return Ok(false); }&#xa;                            &quot;$in&quot; =&gt; {&#xa;                                let arr = op_value.as_array().ok_or(QueryError)?;&#xa;                                if !arr.contains(&amp;doc_value.unwrap_or(&amp;Value::Null)) {&#xa;                                    return Ok(false);&#xa;                                }&#xa;                            }&#xa;                            &quot;$exists&quot; =&gt; {&#xa;                                let should_exist = op_value.as_bool().ok_or(QueryError)?;&#xa;                                if should_exist != doc_value.is_some() { return Ok(false); }&#xa;                            }&#xa;                            _ =&gt; return Err(MongoLiteError::UnsupportedOperator(op.clone())),&#xa;                        }&#xa;                    }&#xa;                } else {&#xa;                    // Equality: {&quot;name&quot;: &quot;Alice&quot;}&#xa;                    if doc_value != Some(value) { return Ok(false); }&#xa;                }&#xa;            }&#xa;        }&#xa;    }&#xa;    &#xa;    Ok(true)&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="1660" y="510" width="560" height="370" as="geometry" />
        </mxCell>

        <!-- error.rs -->
        <mxCell id="rust_error" value="error.rs" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#b9e0a5;strokeColor=#5a8f3d;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="2270" y="485" width="400" height="410" as="geometry" />
        </mxCell>

        <mxCell id="rust_error_code" value="&#xa;use thiserror::Error;&#xa;&#xa;#[derive(Error, Debug)]&#xa;pub enum MongoLiteError {&#xa;    #[error(&quot;IO error: {0}&quot;)]&#xa;    IoError(#[from] std::io::Error),&#xa;    &#xa;    #[error(&quot;Database corruption: {0}&quot;)]&#xa;    Corruption(String),&#xa;    &#xa;    #[error(&quot;Collection not found: {0}&quot;)]&#xa;    CollectionNotFound(String),&#xa;    &#xa;    #[error(&quot;Collection already exists: {0}&quot;)]&#xa;    CollectionExists(String),&#xa;    &#xa;    #[error(&quot;Document not found&quot;)]&#xa;    DocumentNotFound,&#xa;    &#xa;    #[error(&quot;Serialization error: {0}&quot;)]&#xa;    Serialization(String),&#xa;    &#xa;    #[error(&quot;Deserialization error: {0}&quot;)]&#xa;    Deserialization(String),&#xa;    &#xa;    #[error(&quot;Query error: {0}&quot;)]&#xa;    QueryError(String),&#xa;    &#xa;    #[error(&quot;Unsupported operator: {0}&quot;)]&#xa;    UnsupportedOperator(String),&#xa;    &#xa;    #[error(&quot;Index error: {0}&quot;)]&#xa;    IndexError(String),&#xa;    &#xa;    #[error(&quot;WAL error: {0}&quot;)]&#xa;    WalError(String),&#xa;}&#xa;&#xa;pub type Result&lt;T&gt; = std::result::Result&lt;T, MongoLiteError&gt;;&#xa;&#xa;// PyO3 conversion in bindings:&#xa;impl From&lt;MongoLiteError&gt; for PyErr {&#xa;    fn from(err: MongoLiteError) -&gt; PyErr {&#xa;        match err {&#xa;            IoError(_) =&gt; PyIOError::new_err(err.to_string()),&#xa;            CollectionNotFound(_) =&gt; PyKeyError::new_err(err.to_string()),&#xa;            _ =&gt; PyRuntimeError::new_err(err.to_string()),&#xa;        }&#xa;    }&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="2280" y="510" width="380" height="370" as="geometry" />
        </mxCell>

        <!-- ========== LAYER 3: Storage Engine ========== -->
        <mxCell id="storage_layer" value="Storage Engine (ironbase-core/src/storage/)" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#fff2cc;strokeColor=#d6b656;verticalAlign=top;fontSize=16;fontStyle=1;align=center;" vertex="1" parent="1">
          <mxGeometry x="40" y="960" width="3120" height="680" as="geometry" />
        </mxCell>

        <!-- storage/mod.rs -->
        <mxCell id="storage_mod" value="storage/mod.rs" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#ffe599;strokeColor=#b89400;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="80" y="1005" width="620" height="610" as="geometry" />
        </mxCell>

        <mxCell id="storage_mod_code" value="&#xa;pub const HEADER_SIZE: u64 = 256;  // Bincode-serialized header&#xa;&#xa;#[derive(Serialize, Deserialize, Clone)]&#xa;pub struct Header {&#xa;    pub magic: [u8; 8],              // &quot;MONGOLTE&quot;&#xa;    pub version: u32,                // 2 = dynamic metadata&#xa;    pub page_size: u32,              // Default 4096&#xa;    pub collection_count: u32,       // Number of collections&#xa;    pub free_list_head: u64,         // For future free space mgmt&#xa;    pub index_section_offset: u64,   // For future indexing&#xa;    &#xa;    // Version 2+ fields:&#xa;    #[serde(default)]&#xa;    pub metadata_offset: u64,        // Where metadata starts (at file END)&#xa;    #[serde(default)]&#xa;    pub metadata_size: u64,          // Size of metadata in bytes&#xa;}&#xa;&#xa;#[derive(Serialize, Deserialize, Clone)]&#xa;pub struct CollectionMeta {&#xa;    pub name: String,&#xa;    pub document_count: u64,&#xa;    pub data_offset: u64,            // Always HEADER_SIZE in v2&#xa;    pub index_offset: u64,&#xa;    pub last_id: i64,                // For auto-increment IDs&#xa;    &#xa;    // Custom serialization with catalog_serde&#xa;    #[serde(with = &quot;crate::storage::catalog_serde&quot;)]&#xa;    pub document_catalog: HashMap&lt;DocumentId, u64&gt;,  // id -&gt; file offset&#xa;}&#xa;&#xa;pub struct StorageEngine {&#xa;    pub(crate) file: File,&#xa;    pub(crate) file_path: String,&#xa;    pub(crate) header: Header,&#xa;    pub(crate) collections: HashMap&lt;String, CollectionMeta&gt;,&#xa;    pub(crate) mmap: Option&lt;MmapMut&gt;,  // For files &lt; 1GB&#xa;}&#xa;&#xa;impl StorageEngine {&#xa;    pub fn open(path: &amp;str) -&gt; Result&lt;Self&gt; {&#xa;        let mut file = OpenOptions::new()&#xa;            .read(true).write(true).create(true).open(path)?;&#xa;        &#xa;        if file.metadata()?.len() == 0 {&#xa;            // New database: write header&#xa;            Self::init_new_file(&amp;mut file)?;&#xa;        }&#xa;        &#xa;        let (header, collections) = Self::load_metadata(&amp;mut file)?;&#xa;        &#xa;        let mmap = if file.metadata()?.len() &lt; 1_000_000_000 {&#xa;            unsafe { MmapOptions::new().map_mut(&amp;file).ok() }&#xa;        } else {&#xa;            None&#xa;        };&#xa;        &#xa;        Ok(StorageEngine {&#xa;            file, file_path: path.to_string(),&#xa;            header, collections, mmap,&#xa;        })&#xa;    }&#xa;    &#xa;    pub fn create_collection(&amp;mut self, name: &amp;str) -&gt; Result&lt;()&gt; {&#xa;        if self.collections.contains_key(name) {&#xa;            return Err(MongoLiteError::CollectionExists(name.to_string()));&#xa;        }&#xa;        &#xa;        let meta = CollectionMeta {&#xa;            name: name.to_string(),&#xa;            document_count: 0,&#xa;            data_offset: HEADER_SIZE,&#xa;            index_offset: HEADER_SIZE,&#xa;            last_id: 0,&#xa;            document_catalog: HashMap::new(),&#xa;        };&#xa;        &#xa;        self.collections.insert(name.to_string(), meta);&#xa;        self.header.collection_count += 1;&#xa;        &#xa;        // IMPORTANT: No flush_metadata() here!&#xa;        // Lazy flush on: close(), compact(), explicit flush()&#xa;        &#xa;        Ok(())&#xa;    }&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="90" y="1030" width="600" height="570" as="geometry" />
        </mxCell>

        <!-- storage/metadata.rs -->
        <mxCell id="storage_metadata" value="storage/metadata.rs" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#ffe599;strokeColor=#b89400;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="740" y="1005" width="700" height="610" as="geometry" />
        </mxCell>

        <mxCell id="storage_metadata_code" value="&#xa;impl StorageEngine {&#xa;    /// Flush metadata to disk (DYNAMIC METADATA - Version 2)&#xa;    pub(crate) fn flush_metadata(&amp;mut self) -&gt; Result&lt;()&gt; {&#xa;        // ALGORITHM: Dynamic metadata positioning&#xa;        // 1. Find END of document data by scanning catalog&#xa;        // 2. Serialize metadata to buffer&#xa;        // 3. Truncate file at document end&#xa;        // 4. Append metadata at file end&#xa;        // 5. Update header with metadata_offset and metadata_size&#xa;        &#xa;        let data_offset = HEADER_SIZE;&#xa;        &#xa;        // Update collection offsets&#xa;        for meta in self.collections.values_mut() {&#xa;            meta.data_offset = data_offset;&#xa;            meta.index_offset = data_offset;&#xa;        }&#xa;        &#xa;        // Serialize metadata&#xa;        let mut metadata_buffer = Cursor::new(Vec::new());&#xa;        Self::write_metadata_body(&amp;mut metadata_buffer, &amp;self.collections)?;&#xa;        let metadata_bytes = metadata_buffer.into_inner();&#xa;        let metadata_size = metadata_bytes.len() as u64;&#xa;        &#xa;        // CRITICAL: Find actual end of documents by scanning catalog&#xa;        let mut max_doc_offset: u64 = HEADER_SIZE;&#xa;        &#xa;        for coll_meta in self.collections.values() {&#xa;            for &amp;doc_offset in coll_meta.document_catalog.values() {&#xa;                if doc_offset &gt; max_doc_offset {&#xa;                    max_doc_offset = doc_offset;&#xa;                }&#xa;            }&#xa;        }&#xa;        &#xa;        // Read last document size to find exact end&#xa;        let metadata_offset = if max_doc_offset &gt; HEADER_SIZE {&#xa;            self.file.seek(SeekFrom::Start(max_doc_offset))?;&#xa;            &#xa;            let mut len_bytes = [0u8; 4];&#xa;            if self.file.read_exact(&amp;mut len_bytes).is_ok() {&#xa;                let doc_len = u32::from_le_bytes(len_bytes) as u64;&#xa;                max_doc_offset + 4 + doc_len  // offset + len_prefix + doc_data&#xa;            } else {&#xa;                self.file.metadata()?.len()  // Fallback to file end&#xa;            }&#xa;        } else {&#xa;            HEADER_SIZE  // No documents yet&#xa;        };&#xa;        &#xa;        // Truncate file to remove old metadata&#xa;        self.file.set_len(metadata_offset)?;&#xa;        &#xa;        // Write metadata at end&#xa;        self.file.seek(SeekFrom::Start(metadata_offset))?;&#xa;        self.file.write_all(&amp;metadata_bytes)?;&#xa;        &#xa;        // Update header&#xa;        self.header.metadata_offset = metadata_offset;&#xa;        self.header.metadata_size = metadata_size;&#xa;        &#xa;        // Rewrite header&#xa;        self.file.seek(SeekFrom::Start(0))?;&#xa;        let header_bytes = bincode::serialize(&amp;self.header)&#xa;            .map_err(|e| MongoLiteError::Serialization(e.to_string()))?;&#xa;        self.file.write_all(&amp;header_bytes)?;&#xa;        &#xa;        self.file.sync_all()?;&#xa;        &#xa;        Ok(())&#xa;    }&#xa;    &#xa;    fn write_metadata_body&lt;W: Write&gt;(&#xa;        writer: &amp;mut W,&#xa;        collections: &amp;HashMap&lt;String, CollectionMeta&gt;,&#xa;    ) -&gt; Result&lt;()&gt; {&#xa;        // [collection_count: u32]&#xa;        let count = (collections.len() as u32).to_le_bytes();&#xa;        writer.write_all(&amp;count)?;&#xa;        &#xa;        // [len: u32][JSON bytes] for each collection&#xa;        for meta in collections.values() {&#xa;            let meta_bytes = serde_json::to_vec(meta)?;&#xa;            let len = (meta_bytes.len() as u32).to_le_bytes();&#xa;            writer.write_all(&amp;len)?;&#xa;            writer.write_all(&amp;meta_bytes)?;&#xa;        }&#xa;        &#xa;        Ok(())&#xa;    }&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="750" y="1030" width="680" height="570" as="geometry" />
        </mxCell>

        <!-- storage/io.rs -->
        <mxCell id="storage_io" value="storage/io.rs" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#ffe599;strokeColor=#b89400;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="1480" y="1005" width="560" height="610" as="geometry" />
        </mxCell>

        <mxCell id="storage_io_code" value="&#xa;impl StorageEngine {&#xa;    /// Write document to file (append-only)&#xa;    pub fn write_document(&#xa;        &amp;mut self,&#xa;        collection: &amp;str,&#xa;        doc_id: &amp;DocumentId,&#xa;        data: &amp;[u8]&#xa;    ) -&gt; Result&lt;u64&gt; {&#xa;        // ALGORITHM: Append-only write&#xa;        // 1. Seek to end of file&#xa;        // 2. Write [len: u32][data: bytes]&#xa;        // 3. Update document_catalog and document_count&#xa;        // 4. NO metadata flush (lazy flush)&#xa;        &#xa;        let file_end = self.file.seek(SeekFrom::End(0))?;&#xa;        let write_pos = std::cmp::max(file_end, HEADER_SIZE);&#xa;        let absolute_offset = self.file.seek(SeekFrom::Start(write_pos))?;&#xa;        &#xa;        // Write length prefix + data&#xa;        let len = (data.len() as u32).to_le_bytes();&#xa;        self.file.write_all(&amp;len)?;&#xa;        self.file.write_all(data)?;&#xa;        &#xa;        // Update catalog&#xa;        let meta = self.get_collection_meta_mut(collection)&#xa;            .ok_or_else(|| MongoLiteError::CollectionNotFound(collection.to_string()))?;&#xa;        &#xa;        meta.document_catalog.insert(doc_id.clone(), absolute_offset);&#xa;        meta.document_count += 1;&#xa;        &#xa;        Ok(absolute_offset)&#xa;    }&#xa;    &#xa;    /// Read document data from offset&#xa;    pub fn read_data(&amp;self, offset: u64) -&gt; Result&lt;Vec&lt;u8&gt;&gt; {&#xa;        if let Some(ref mmap) = self.mmap {&#xa;            // Fast path: memory-mapped read&#xa;            let offset_usize = offset as usize;&#xa;            let len_bytes = &amp;mmap[offset_usize..offset_usize + 4];&#xa;            let len = u32::from_le_bytes([&#xa;                len_bytes[0], len_bytes[1], len_bytes[2], len_bytes[3]&#xa;            ]) as usize;&#xa;            &#xa;            let data_start = offset_usize + 4;&#xa;            let data_end = data_start + len;&#xa;            &#xa;            Ok(mmap[data_start..data_end].to_vec())&#xa;        } else {&#xa;            // Slow path: regular file I/O&#xa;            let mut file = &amp;self.file;&#xa;            file.seek(SeekFrom::Start(offset))?;&#xa;            &#xa;            let mut len_bytes = [0u8; 4];&#xa;            file.read_exact(&amp;mut len_bytes)?;&#xa;            let len = u32::from_le_bytes(len_bytes) as usize;&#xa;            &#xa;            let mut data = vec![0u8; len];&#xa;            file.read_exact(&amp;mut data)?;&#xa;            &#xa;            Ok(data)&#xa;        }&#xa;    }&#xa;    &#xa;    pub fn read_document(&amp;self, collection: &amp;str, doc_id: &amp;DocumentId) -&gt; Result&lt;Value&gt; {&#xa;        let meta = self.get_collection_meta(collection)?;&#xa;        let offset = meta.document_catalog.get(doc_id)&#xa;            .ok_or(MongoLiteError::DocumentNotFound)?;&#xa;        &#xa;        let data = self.read_data(*offset)?;&#xa;        let doc: Value = serde_json::from_slice(&amp;data)?;&#xa;        &#xa;        Ok(doc)&#xa;    }&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="1490" y="1030" width="540" height="570" as="geometry" />
        </mxCell>

        <!-- storage/compaction.rs -->
        <mxCell id="storage_compaction" value="storage/compaction.rs" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#ffe599;strokeColor=#b89400;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="2080" y="1005" width="600" height="610" as="geometry" />
        </mxCell>

        <mxCell id="storage_compaction_code" value="&#xa;pub struct CompactionConfig {&#xa;    pub chunk_size: usize,  // Default: 1000 docs/chunk&#xa;}&#xa;&#xa;pub struct CompactionStats {&#xa;    pub size_before: u64,&#xa;    pub size_after: u64,&#xa;    pub documents_scanned: u64,&#xa;    pub documents_kept: u64,&#xa;    pub tombstones_removed: u64,&#xa;    pub peak_memory_mb: u64,&#xa;}&#xa;&#xa;impl StorageEngine {&#xa;    pub fn compact_with_config(&amp;mut self, config: &amp;CompactionConfig) -&gt; Result&lt;CompactionStats&gt; {&#xa;        // ALGORITHM: Chunked compaction (Version 2 output)&#xa;        // 1. Flush metadata first (to know where docs end)&#xa;        // 2. Scan document data up to metadata_offset&#xa;        // 3. Collect latest version of each doc (HashMap by ID)&#xa;        // 4. Process in chunks to limit memory usage&#xa;        // 5. Write to temp file: Header → Documents → Metadata (v2)&#xa;        // 6. Replace old file with compacted file&#xa;        &#xa;        self.flush_metadata()?;  // CRITICAL: ensures metadata_offset is set&#xa;        &#xa;        let temp_path = format!(&quot;{}.compact&quot;, self.file_path);&#xa;        let mut stats = CompactionStats::default();&#xa;        stats.size_before = self.file.metadata()?.len();&#xa;        &#xa;        // Only scan up to metadata_offset (v2)&#xa;        let file_len = if self.header.version &gt;= 2 &amp;&amp; self.header.metadata_offset &gt; 0 {&#xa;            self.header.metadata_offset&#xa;        } else {&#xa;            self.file_len()?  // v1 fallback&#xa;        };&#xa;        &#xa;        // Create temp file&#xa;        let mut new_file = OpenOptions::new()&#xa;            .read(true).write(true).create(true).truncate(true)&#xa;            .open(&amp;temp_path)?;&#xa;        &#xa;        // Write header only (no metadata yet)&#xa;        new_file.seek(SeekFrom::Start(0))?;&#xa;        let header_bytes = bincode::serialize(&amp;self.header)?;&#xa;        new_file.write_all(&amp;header_bytes)?;&#xa;        &#xa;        // Write documents from HEADER_SIZE&#xa;        new_file.seek(SeekFrom::Start(HEADER_SIZE))?;&#xa;        let mut write_offset = HEADER_SIZE;&#xa;        &#xa;        // Collect docs in chunks&#xa;        let mut collection_docs: HashMap&lt;String, HashMap&lt;DocumentId, Value&gt;&gt; = HashMap::new();&#xa;        for coll_name in self.collections.keys() {&#xa;            collection_docs.insert(coll_name.clone(), HashMap::new());&#xa;        }&#xa;        &#xa;        let mut current_offset = HEADER_SIZE;&#xa;        let mut chunk_count = 0;&#xa;        &#xa;        while current_offset &lt; file_len {&#xa;            match self.read_data(current_offset) {&#xa;                Ok(doc_bytes) =&gt; {&#xa;                    stats.documents_scanned += 1;&#xa;                    &#xa;                    if let Ok(doc) = serde_json::from_slice::&lt;Value&gt;(&amp;doc_bytes) {&#xa;                        let coll = doc.get(&quot;_collection&quot;).and_then(|v| v.as_str()).unwrap_or(&quot;&quot;);&#xa;                        &#xa;                        if let Some(docs_by_id) = collection_docs.get_mut(coll) {&#xa;                            if let Some(id_val) = doc.get(&quot;_id&quot;) {&#xa;                                if let Ok(doc_id) = serde_json::from_value::&lt;DocumentId&gt;(id_val.clone()) {&#xa;                                    docs_by_id.insert(doc_id, doc);&#xa;                                    chunk_count += 1;&#xa;                                    &#xa;                                    // Flush chunk if full&#xa;                                    if chunk_count &gt;= config.chunk_size {&#xa;                                        for (coll_name, docs) in collection_docs.iter_mut() {&#xa;                                            if !docs.is_empty() {&#xa;                                                write_offset = self.flush_compaction_chunk(&#xa;                                                    &amp;mut new_file, &amp;mut new_collections,&#xa;                                                    coll_name, docs, write_offset, &amp;mut stats&#xa;                                                )?;&#xa;                                                docs.clear();&#xa;                                            }&#xa;                                        }&#xa;                                        chunk_count = 0;&#xa;                                    }&#xa;                                }&#xa;                            }&#xa;                        }&#xa;                    }&#xa;                    &#xa;                    current_offset += 4 + doc_bytes.len() as u64;&#xa;                }&#xa;                Err(_) =&gt; break,&#xa;            }&#xa;        }&#xa;        &#xa;        // Flush remaining&#xa;        for (coll_name, docs) in collection_docs.iter_mut() {&#xa;            if !docs.is_empty() {&#xa;                write_offset = self.flush_compaction_chunk(/* ... */)?;&#xa;            }&#xa;        }&#xa;        &#xa;        // Write metadata at END (version 2)&#xa;        let metadata_offset = write_offset;&#xa;        // ... serialize and write metadata ...&#xa;        // ... update header with metadata_offset and metadata_size ...&#xa;        &#xa;        stats.size_after = new_file.metadata()?.len();&#xa;        &#xa;        // Replace old file&#xa;        fs::rename(&amp;temp_path, &amp;self.file_path)?;&#xa;        // Reload&#xa;        &#xa;        Ok(stats)&#xa;    }&#xa;}" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="2090" y="1030" width="580" height="570" as="geometry" />
        </mxCell>

        <!-- catalog_serde.rs -->
        <mxCell id="storage_catalog" value="storage/catalog_serde.rs" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#ffe599;strokeColor=#b89400;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="2720" y="1005" width="420" height="610" as="geometry" />
        </mxCell>

        <mxCell id="storage_catalog_code" value="&#xa;/// Custom serialization for document_catalog&#xa;/// Preserves DocumentId type information&#xa;/// Format: [[type_tag, value, offset], ...]&#xa;&#xa;pub fn serialize&lt;S&gt;(&#xa;    catalog: &amp;HashMap&lt;DocumentId, u64&gt;,&#xa;    serializer: S&#xa;) -&gt; Result&lt;S::Ok, S::Error&gt;&#xa;where&#xa;    S: Serializer,&#xa;{&#xa;    let mut seq = serializer.serialize_seq(Some(catalog.len()))?;&#xa;    &#xa;    for (id, &amp;offset) in catalog {&#xa;        let entry = match id {&#xa;            DocumentId::Int(n) =&gt; {&#xa;                json!([0, n, offset])  // type=0: Int&#xa;            }&#xa;            DocumentId::String(s) =&gt; {&#xa;                json!([1, s, offset])  // type=1: String&#xa;            }&#xa;            DocumentId::ObjectId(bytes) =&gt; {&#xa;                json!([2, hex::encode(bytes), offset])  // type=2: ObjectId&#xa;            }&#xa;        };&#xa;        seq.serialize_element(&amp;entry)?;&#xa;    }&#xa;    &#xa;    seq.end()&#xa;}&#xa;&#xa;pub fn deserialize&lt;'de, D&gt;(&#xa;    deserializer: D&#xa;) -&gt; Result&lt;HashMap&lt;DocumentId, u64&gt;, D::Error&gt;&#xa;where&#xa;    D: Deserializer&lt;'de&gt;,&#xa;{&#xa;    let entries: Vec&lt;Value&gt; = Vec::deserialize(deserializer)?;&#xa;    let mut catalog = HashMap::new();&#xa;    &#xa;    for entry in entries {&#xa;        let arr = entry.as_array()&#xa;            .ok_or_else(|| serde::de::Error::custom(&quot;Expected array&quot;))?;&#xa;        &#xa;        let type_tag = arr[0].as_u64()&#xa;            .ok_or_else(|| serde::de::Error::custom(&quot;Invalid type tag&quot;))?;&#xa;        let offset = arr[2].as_u64()&#xa;            .ok_or_else(|| serde::de::Error::custom(&quot;Invalid offset&quot;))?;&#xa;        &#xa;        let doc_id = match type_tag {&#xa;            0 =&gt; DocumentId::Int(arr[1].as_i64().unwrap()),&#xa;            1 =&gt; DocumentId::String(arr[1].as_str().unwrap().to_string()),&#xa;            2 =&gt; {&#xa;                let hex_str = arr[1].as_str().unwrap();&#xa;                let bytes = hex::decode(hex_str)&#xa;                    .map_err(|e| serde::de::Error::custom(e))?;&#xa;                let mut oid = [0u8; 12];&#xa;                oid.copy_from_slice(&amp;bytes);&#xa;                DocumentId::ObjectId(oid)&#xa;            }&#xa;            _ =&gt; return Err(serde::de::Error::custom(&quot;Unknown type tag&quot;)),&#xa;        };&#xa;        &#xa;        catalog.insert(doc_id, offset);&#xa;    }&#xa;    &#xa;    Ok(catalog)&#xa;}&#xa;&#xa;// This fixes the index persistence bug where&#xa;// DocumentId type info was lost during JSON serialization&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="2730" y="1030" width="400" height="570" as="geometry" />
        </mxCell>

        <!-- ========== LAYER 4: File Format ========== -->
        <mxCell id="file_layer" value="File Format (.mlite)" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#ffe6cc;strokeColor=#d79b00;verticalAlign=top;fontSize=16;fontStyle=1;align=center;" vertex="1" parent="1">
          <mxGeometry x="40" y="1680" width="1520" height="400" as="geometry" />
        </mxCell>

        <!-- Version 2 Format -->
        <mxCell id="file_v2_detail" value="Version 2 - Dynamic Metadata (Current)" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#ffd966;strokeColor=#cc6600;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="820" y="1725" width="710" height="330" as="geometry" />
        </mxCell>

        <mxCell id="file_v2_detail_code" value="&#xa;File Layout (byte-level):&#xa;&#xa;┌───────────────────────────────────────────────────────────┐&#xa;│ Offset 0: Header (256 bytes, bincode)                    │&#xa;│   - magic: [u8; 8] = *b&quot;MONGOLTE&quot;                        │&#xa;│   - version: u32 = 2                                      │&#xa;│   - page_size: u32 = 4096                                 │&#xa;│   - collection_count: u32                                 │&#xa;│   - free_list_head: u64 = 0                               │&#xa;│   - index_section_offset: u64 = 0                         │&#xa;│   - metadata_offset: u64  ← Points to metadata location  │&#xa;│   - metadata_size: u64    ← Size of metadata             │&#xa;├───────────────────────────────────────────────────────────┤&#xa;│ Offset 256: Document Data (append-only)                  │&#xa;│   [u32 len][JSON bytes]                                   │&#xa;│   [u32 len][JSON bytes]                                   │&#xa;│   ...                                                     │&#xa;│   [u32 len][JSON bytes]  ← Last document                  │&#xa;├───────────────────────────────────────────────────────────┤&#xa;│ Offset = metadata_offset: Metadata (dynamic size)         │&#xa;│   [u32 collection_count]                                  │&#xa;│   For each collection:                                    │&#xa;│     [u32 len][JSON CollectionMeta]                        │&#xa;│       {                                                   │&#xa;│         &quot;name&quot;: &quot;users&quot;,                                  │&#xa;│         &quot;document_count&quot;: 1000,                           │&#xa;│         &quot;data_offset&quot;: 256,                               │&#xa;│         &quot;last_id&quot;: 1000,                                   │&#xa;│         &quot;document_catalog&quot;: [                             │&#xa;│           [0, 1, 256],    ← [type, id_value, offset]     │&#xa;│           [0, 2, 512],                                    │&#xa;│           ...                                             │&#xa;│         ]                                                 │&#xa;│       }                                                   │&#xa;└───────────────────────────────────────────────────────────┘&#xa;&#xa;Benefits:&#xa;✓ No 10MB bloat (100 docs = 8.82 KB instead of 10 MB)&#xa;✓ Unlimited metadata size (tested with 15 MB / 650K docs)&#xa;✓ O(1) insert performance (lazy flush)&#xa;✓ Backward compatible with v1&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="830" y="1750" width="690" height="290" as="geometry" />
        </mxCell>

        <!-- Version 1 Format -->
        <mxCell id="file_v1_detail" value="Version 1 - Fixed Metadata (Legacy)" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#ffd966;strokeColor=#cc6600;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="80" y="1725" width="700" height="330" as="geometry" />
        </mxCell>

        <mxCell id="file_v1_detail_code" value="&#xa;File Layout (byte-level):&#xa;&#xa;┌───────────────────────────────────────────────────────────┐&#xa;│ Offset 0: Header (256 bytes)                             │&#xa;│   - version: u32 = 1                                      │&#xa;│   - metadata_offset: u64 = 0 (not used)                   │&#xa;├───────────────────────────────────────────────────────────┤&#xa;│ Offset 256: Metadata (FIXED 10 MB reservation)            │&#xa;│   [u32 collection_count]                                  │&#xa;│   [u32 len][JSON CollectionMeta]                          │&#xa;│   ...                                                     │&#xa;│   [unused space padded to 10 MB]                          │&#xa;├───────────────────────────────────────────────────────────┤&#xa;│ Offset 10485760: Document Data                            │&#xa;│   [u32 len][JSON bytes]                                   │&#xa;│   ...                                                     │&#xa;└───────────────────────────────────────────────────────────┘&#xa;&#xa;Problems:&#xa;❌ 10 MB wasted for small databases (100 docs = 10 MB)&#xa;❌ Metadata size limited to 10 MB&#xa;❌ Can't scale beyond ~100K documents&#xa;&#xa;Migration to v2:&#xa;- Automatic on first flush after opening v1 database&#xa;- No data loss during conversion&#xa;- Metadata relocated from offset 256 to file end&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="90" y="1750" width="680" height="290" as="geometry" />
        </mxCell>

        <!-- ========== LAYER 5: WAL ========== -->
        <mxCell id="wal_layer" value="Write-Ahead Log (WAL) - Durability Mechanism" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#f8cecc;strokeColor=#b85450;verticalAlign=top;fontSize=16;fontStyle=1;align=center;" vertex="1" parent="1">
          <mxGeometry x="1600" y="1680" width="1560" height="400" as="geometry" />
        </mxCell>

        <mxCell id="wal_detail" value="wal.rs (Write-Ahead Log Implementation)" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#f5a3a3;strokeColor=#a03030;fontSize=13;fontStyle=1;align=left;spacingLeft=15;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="1640" y="1725" width="1480" height="330" as="geometry" />
        </mxCell>

        <mxCell id="wal_detail_code" value="&#xa;pub struct WriteAheadLog {&#xa;    file: File,&#xa;    path: String,&#xa;}&#xa;&#xa;#[derive(Serialize, Deserialize)]&#xa;pub enum WalEntry {&#xa;    Insert { collection: String, doc_id: DocumentId, data: Vec&lt;u8&gt; },&#xa;    Update { collection: String, doc_id: DocumentId, old_data: Vec&lt;u8&gt;, new_data: Vec&lt;u8&gt; },&#xa;    Delete { collection: String, doc_id: DocumentId },&#xa;    CreateCollection { name: String },&#xa;    DropCollection { name: String },&#xa;}&#xa;&#xa;impl WriteAheadLog {&#xa;    pub fn open(path: &amp;str) -&gt; Result&lt;Self&gt; { /* ... */ }&#xa;    &#xa;    pub fn append(&amp;mut self, entry: &amp;WalEntry) -&gt; Result&lt;()&gt; {&#xa;        // ALGORITHM: Append-only WAL write&#xa;        // 1. Serialize entry to JSON&#xa;        // 2. Write [u32 len][JSON bytes] to WAL file&#xa;        // 3. Sync to disk (fsync)&#xa;        // 4. Return success&#xa;        &#xa;        let entry_bytes = serde_json::to_vec(entry)?;&#xa;        let len = (entry_bytes.len() as u32).to_le_bytes();&#xa;        &#xa;        self.file.write_all(&amp;len)?;&#xa;        self.file.write_all(&amp;entry_bytes)?;&#xa;        self.file.sync_all()?;  // Force disk write&#xa;        &#xa;        Ok(())&#xa;    }&#xa;    &#xa;    pub fn replay&lt;F&gt;(&amp;mut self, mut apply: F) -&gt; Result&lt;()&gt;&#xa;    where&#xa;        F: FnMut(&amp;WalEntry) -&gt; Result&lt;()&gt;,&#xa;    {&#xa;        // ALGORITHM: WAL recovery on database open&#xa;        // 1. Scan WAL file from beginning&#xa;        // 2. For each entry, apply to storage engine&#xa;        // 3. Rebuild document_catalog from applied entries&#xa;        // 4. Flush metadata to finalize recovery&#xa;        // 5. Truncate WAL (clear after successful recovery)&#xa;        &#xa;        self.file.seek(SeekFrom::Start(0))?;&#xa;        &#xa;        loop {&#xa;            let mut len_bytes = [0u8; 4];&#xa;            match self.file.read_exact(&amp;mut len_bytes) {&#xa;                Ok(_) =&gt; {&#xa;                    let len = u32::from_le_bytes(len_bytes) as usize;&#xa;                    let mut entry_bytes = vec![0u8; len];&#xa;                    self.file.read_exact(&amp;mut entry_bytes)?;&#xa;                    &#xa;                    let entry: WalEntry = serde_json::from_slice(&amp;entry_bytes)?;&#xa;                    apply(&amp;entry)?;  // Apply to storage&#xa;                }&#xa;                Err(ref e) if e.kind() == io::ErrorKind::UnexpectedEof =&gt; break,&#xa;                Err(e) =&gt; return Err(e.into()),&#xa;            }&#xa;        }&#xa;        &#xa;        // Clear WAL after successful recovery&#xa;        self.file.set_len(0)?;&#xa;        self.file.sync_all()?;&#xa;        &#xa;        Ok(())&#xa;    }&#xa;}&#xa;&#xa;Transaction Safety with Lazy Metadata Flush:&#xa;&#xa;Q: Is lazy metadata flush safe?&#xa;A: YES! WAL provides durability independent of metadata flush.&#xa;&#xa;Scenario: Insert document, then crash BEFORE metadata flush&#xa;1. Document written to .mlite file (append-only)&#xa;2. WAL entry written and synced to .wal file&#xa;3. [CRASH] - metadata NOT flushed, catalog NOT updated on disk&#xa;4. [RECOVERY] - WAL replayed:&#xa;   - Read WAL entries&#xa;   - Re-insert documents into catalog (in-memory)&#xa;   - Flush metadata to finalize&#xa;5. Result: No data loss! Document recovered from WAL.&#xa;&#xa;Key Insight: WAL durability ≠ Metadata durability&#xa;- WAL ensures operations can be replayed&#xa;- Metadata flush is an optimization (reduces recovery time)&#xa;- Lazy flush improves write performance without compromising safety&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="1650" y="1750" width="1460" height="290" as="geometry" />
        </mxCell>

        <!-- ========== Data Flow Diagrams ========== -->
        <mxCell id="dataflow_layer" value="Data Flow - Key Operations" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#e1d5e7;strokeColor=#9673a6;verticalAlign=top;fontSize=16;fontStyle=1;align=center;" vertex="1" parent="1">
          <mxGeometry x="40" y="2120" width="3120" height="220" as="geometry" />
        </mxCell>

        <!-- Insert Flow -->
        <mxCell id="insert_flow" value="INSERT Operation Flow" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#d0cee2;strokeColor=#56517e;fontSize=12;fontStyle=1;align=left;spacingLeft=10;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="80" y="2165" width="600" height="150" as="geometry" />
        </mxCell>

        <mxCell id="insert_flow_text" value="&#xa;Python: collection.insert_one({...})&#xa;  ↓ PyO3 conversion (python_to_json)&#xa;Rust: Collection::insert_one(doc: Value)&#xa;  ↓ Generate/validate _id&#xa;  ↓ Inject _collection field&#xa;  ↓ Serialize to JSON bytes&#xa;Storage: write_document(collection, doc_id, bytes)&#xa;  ↓ Seek to file end&#xa;  ↓ Write [len][data]&#xa;  ↓ Update catalog: catalog.insert(doc_id, offset)&#xa;  ↓ Increment document_count&#xa;  ↓ NO metadata flush! (lazy)&#xa;WAL: append(WalEntry::Insert)&#xa;  ↓ Write to .wal file&#xa;  ↓ fsync()&#xa;Return: InsertOneResult { inserted_id }&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="90" y="2185" width="580" height="120" as="geometry" />
        </mxCell>

        <!-- Find Flow -->
        <mxCell id="find_flow" value="FIND Operation Flow" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#d0cee2;strokeColor=#56517e;fontSize=12;fontStyle=1;align=left;spacingLeft=10;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="720" y="2165" width="600" height="150" as="geometry" />
        </mxCell>

        <mxCell id="find_flow_text" value="&#xa;Python: list(collection.find({&quot;age&quot;: {&quot;$gt&quot;: 18}}))&#xa;  ↓ PyO3 conversion&#xa;Rust: Collection::find(filter: Value)&#xa;  ↓ Acquire read lock: storage.read()&#xa;  ↓ Get collection metadata&#xa;  ↓ For each (doc_id, offset) in catalog:&#xa;      ↓ Read document: read_data(offset)&#xa;      ↓   - If mmap: direct memory access&#xa;      ↓   - Else: file.seek + read&#xa;      ↓ Deserialize JSON to Value&#xa;      ↓ Skip if _tombstone = true&#xa;      ↓ Apply filter: matches_filter(doc, filter)&#xa;      ↓ If match: add to results&#xa;  ↓ Return Vec&lt;Value&gt;&#xa;  ↓ PyO3 conversion (json_to_python)&#xa;Python: [dict, dict, ...]&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="730" y="2185" width="580" height="120" as="geometry" />
        </mxCell>

        <!-- Compaction Flow -->
        <mxCell id="compact_flow" value="COMPACTION Operation Flow" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#d0cee2;strokeColor=#56517e;fontSize=12;fontStyle=1;align=left;spacingLeft=10;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="1360" y="2165" width="600" height="150" as="geometry" />
        </mxCell>

        <mxCell id="compact_flow_text" value="&#xa;storage.compact()&#xa;  ↓ flush_metadata() first (critical!)&#xa;  ↓ Create temp file: {path}.compact&#xa;  ↓ Write header only (no metadata)&#xa;  ↓ Scan docs up to metadata_offset&#xa;  ↓ For each doc:&#xa;      ↓ Deserialize, extract _collection and _id&#xa;      ↓ Store in HashMap&lt;coll, HashMap&lt;id, doc&gt;&gt;&#xa;      ↓ Latest version overwrites previous&#xa;      ↓ If chunk full (1000 docs):&#xa;          ↓ Write docs to temp file&#xa;          ↓ Clear chunk (free memory)&#xa;  ↓ Flush remaining chunks&#xa;  ↓ Write metadata at END (v2 format)&#xa;  ↓ Update header with metadata_offset/size&#xa;  ↓ Replace old file with temp file&#xa;  ↓ Reload metadata&#xa;Return: CompactionStats&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="1370" y="2185" width="580" height="120" as="geometry" />
        </mxCell>

        <!-- Close Flow -->
        <mxCell id="close_flow" value="CLOSE/FLUSH Operation Flow" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#d0cee2;strokeColor=#56517e;fontSize=12;fontStyle=1;align=left;spacingLeft=10;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="2000" y="2165" width="600" height="150" as="geometry" />
        </mxCell>

        <mxCell id="close_flow_text" value="&#xa;db.close() or db.flush()&#xa;  ↓ Acquire write lock: storage.write()&#xa;  ↓ flush_metadata():&#xa;      ↓ Scan catalog for max document offset&#xa;      ↓ Read last doc size to find exact end&#xa;      ↓ metadata_offset = max_offset + 4 + doc_len&#xa;      ↓ Serialize metadata to buffer&#xa;      ↓ Truncate file at metadata_offset&#xa;      ↓ Write metadata at file end&#xa;      ↓ Update header.metadata_offset&#xa;      ↓ Update header.metadata_size&#xa;      ↓ Rewrite header at offset 0&#xa;      ↓ fsync()&#xa;  ↓ Close WAL file&#xa;Result: Metadata persisted, catalog on disk&#xa;&#xa;Next open: Catalog loaded from disk, no WAL replay needed&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="2010" y="2185" width="580" height="120" as="geometry" />
        </mxCell>

        <!-- Recovery Flow -->
        <mxCell id="recovery_flow" value="CRASH RECOVERY Flow" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#d0cee2;strokeColor=#56517e;fontSize=12;fontStyle=1;align=left;spacingLeft=10;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="2640" y="2165" width="480" height="150" as="geometry" />
        </mxCell>

        <mxCell id="recovery_flow_text" value="&#xa;[CRASH BEFORE METADATA FLUSH]&#xa;Database.open(path)&#xa;  ↓ Open .mlite file&#xa;  ↓ Load metadata (may be stale)&#xa;  ↓ Open .wal file&#xa;  ↓ WAL.replay():&#xa;      ↓ For each WAL entry:&#xa;          ↓ Apply to storage&#xa;          ↓ Update catalog in-memory&#xa;  ↓ flush_metadata() to persist recovered state&#xa;  ↓ Truncate WAL (clear)&#xa;Result: Full recovery, no data loss&#xa;&#xa;Key: WAL durability ensures safety&#xa;even with lazy metadata flush!&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontSize=9;fontFamily=Courier New;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="2650" y="2185" width="460" height="120" as="geometry" />
        </mxCell>

        <!-- ========== Performance Stats Box ========== -->
        <mxCell id="perf_stats" value="Performance Stats - 650K Documents Test" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=#6c8ebf;verticalAlign=top;fontSize=14;fontStyle=1;align=center;" vertex="1" parent="1">
          <mxGeometry x="2360" y="120" width="800" height="280" as="geometry" />
        </mxCell>

        <mxCell id="perf_stats_text" value="&#xa;Hardware: Standard WSL2 Linux (2025-11-12)&#xa;Dataset: 650,000 documents, ~564 MB database&#xa;&#xa;Insert Performance:&#xa;  • Speed: 11,505 docs/sec&#xa;  • Time: 56.5 seconds total&#xa;  • Throughput: 9.99 MB/sec&#xa;  • Memory: Constant (O(1) per insert)&#xa;&#xa;Count Performance:&#xa;  • 650K count: 22.6 seconds&#xa;  • Method: Index-based (catalog size)&#xa;&#xa;Find Performance:&#xa;  • 50K dataset: 7,143 electronics found in 0.29s&#xa;  • 650K dataset: Deserialization bug (separate issue)&#xa;&#xa;Compaction Performance:&#xa;  • Chunk size: 1000 docs/chunk&#xa;  • Memory: O(chunk_size) = constant&#xa;  • Speed: ~5-10% slower than non-chunked&#xa;&#xa;File Size Comparison (Version 1 vs Version 2):&#xa;  • 100 docs:   10.00 MB → 8.82 KB  (99.91% reduction!)&#xa;  • 10K docs:   10.87 MB → 1.12 MB  (89.7% reduction)&#xa;  • 650K docs: ~574 MB → ~564 MB   (1.7% overhead)&#xa;&#xa;Metadata Size:&#xa;  • 650K docs: ~15 MB metadata (within dynamic limit)&#xa;  • No fixed 10 MB reservation&#xa;  • Scales linearly with document count&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=10;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="2370" y="155" width="780" height="235" as="geometry" />
        </mxCell>

        <!-- ========== Thread Safety Box ========== -->
        <mxCell id="thread_safety" value="Thread Safety &amp; Concurrency" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#d5e8d4;strokeColor=#82b366;verticalAlign=top;fontSize=14;fontStyle=1;align=center;" vertex="1" parent="1">
          <mxGeometry x="2360" y="440" width="800" height="220" as="geometry" />
        </mxCell>

        <mxCell id="thread_safety_text" value="&#xa;Arc&lt;RwLock&lt;StorageEngine&gt;&gt;:&#xa;  • Arc: Atomic reference counting for shared ownership&#xa;  • RwLock: Multiple readers OR single writer&#xa;  • Implementation: parking_lot::RwLock (faster than std)&#xa;&#xa;Read Operations (Shared Lock):&#xa;  • find(), find_one(), count_documents()&#xa;  • Multiple threads can read concurrently&#xa;  • No blocking between readers&#xa;&#xa;Write Operations (Exclusive Lock):&#xa;  • insert_one/many(), update_one/many(), delete_one/many()&#xa;  • Only one writer at a time&#xa;  • Blocks all readers during write&#xa;&#xa;Metadata Flush:&#xa;  • Requires write lock (exclusive)&#xa;  • Only happens on: close(), compact(), explicit flush()&#xa;  • NOT on every insert (lazy flush = performance!)&#xa;&#xa;Python GIL Integration:&#xa;  • PyO3 releases GIL during long operations&#xa;  • Rust threads can run in parallel&#xa;  • No Python thread contention on Rust side&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=10;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="2370" y="475" width="780" height="175" as="geometry" />
        </mxCell>

        <!-- ========== Key Algorithms Box ========== -->
        <mxCell id="key_algorithms" value="Key Algorithms Summary" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#fff2cc;strokeColor=#d6b656;verticalAlign=top;fontSize=14;fontStyle=1;align=center;" vertex="1" parent="1">
          <mxGeometry x="2360" y="700" width="800" height="220" as="geometry" />
        </mxCell>

        <mxCell id="key_algorithms_text" value="&#xa;1. Lazy Metadata Flush (O(n) → O(1) per insert):&#xa;   - Keep catalog in memory during operations&#xa;   - Only flush on: close, compact, explicit flush&#xa;   - Result: No I/O on every insert!&#xa;&#xa;2. Catalog-based Offset Calculation:&#xa;   - Scan catalog for max document offset&#xa;   - Read last doc size: seek(max_offset), read 4 bytes&#xa;   - metadata_offset = max_offset + 4 + doc_len&#xa;   - Result: Exact positioning, no wasted space&#xa;&#xa;3. Chunked Compaction (Constant Memory):&#xa;   - Process docs in chunks (default 1000)&#xa;   - HashMap&lt;coll, HashMap&lt;id, doc&gt;&gt; per chunk&#xa;   - Flush chunk → clear memory → next chunk&#xa;   - Result: O(chunk_size) memory regardless of DB size&#xa;&#xa;4. Memory-mapped I/O (&lt;1GB files):&#xa;   - Direct memory access for reads (fast!)&#xa;   - Fallback to file I/O for large files&#xa;   - Zero-copy deserialization&#xa;&#xa;5. WAL Replay (Crash Recovery):&#xa;   - Sequential scan of WAL file&#xa;   - Apply each entry to rebuild catalog&#xa;   - Flush metadata to finalize&#xa;   - Clear WAL after successful recovery&#xa;" style="text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=top;whiteSpace=wrap;rounded=0;fontSize=10;spacingLeft=10;" vertex="1" parent="1">
          <mxGeometry x="2370" y="735" width="780" height="175" as="geometry" />
        </mxCell>

      </root>
    </mxGraphModel>
  </diagram>
</mxfile>
